{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "#import pandas as pd\n",
    "def readData():\n",
    "    #z = pd.read_csv(\"data.csv\",delimiter = \";\")\n",
    "    cnt = 0\n",
    "    fp = open(\"data.csv\",\"r\")   #GlassData\n",
    "    #fp = open(\"test.csv\",\"r\")\n",
    "    dict_data = {} # defaultdict(dict) \n",
    "    dict_count = OrderedDict()\n",
    "    labels = []\n",
    "    len1 = 0\n",
    "    for line in fp:\n",
    "        if cnt == 0:\n",
    "            val = line.strip('\\n').split(\";\")\n",
    "            val1 = val\n",
    "            #label = z[val[len(val) - 1]].unique() \n",
    "            #print(label)\n",
    "        if cnt >= 1:\n",
    "            val = line.strip('\\n').split(\";\")\n",
    "            dict_data[cnt - 1] = val   #{val[i]: 1}\n",
    "            if(val[len(val) - 1]) not in labels:\n",
    "                labels.append(val[len(val) - 1])\n",
    "        cnt += 1\n",
    "    fp.close()\n",
    "    return dict_data, labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def Entropy(dict_data):\n",
    "    labels = {}\n",
    "    for val in dict_data.values():\n",
    "        if(val[len(val) - 1]) in labels.keys():\n",
    "            labels[val[len(val) - 1]] = labels[val[len(val) - 1]] + 1\n",
    "        else:\n",
    "            labels[val[len(val) - 1]] = 1 \n",
    "    sum_label = sum(labels.values())\n",
    "    entropy = 0\n",
    "    for key,val in labels.items():\n",
    "        labels[key] = (float(labels[key])/sum_label)\n",
    "        entropy = entropy + -1*(labels[key] * (math.log(labels[key])/math.log(2)))\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(sorted(dict_data.values(), key=lambda e: e[0], reverse = True))\n",
    "#s = list(set(row[0] for row in (dict_data[val] for val in dict_data.keys())))\n",
    "#d1 = {k:v for (k,v) in dict_data.items() if dict_data[k][0] == '2'}\n",
    "\n",
    "#This function calculates info gain for continuous data and returns the split point with best info gain\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "def continuous_info_gain(dict_data,index,entropy,labels):\n",
    "    sum_less = 0.0\n",
    "    sum_more = 0.0\n",
    "    split_mid_pt = 0.0\n",
    "    split_mid_pt_gain_ratio = 0.0\n",
    "    min_cont_info = 100.0\n",
    "    max_gain_ratio = 0.0\n",
    "    len_data = float(len(dict_data))\n",
    "    sorted_data_list = sorted(dict_data.values(), key=lambda e: e[index], reverse = True)\n",
    "    sorted_data = OrderedDict()\n",
    "    i = 0\n",
    "    for i in range(0,len(sorted_data_list)):\n",
    "        sorted_data[i] = {}\n",
    "        sorted_data[i] = sorted_data_list[i]\n",
    "    unique_val_list = list(map(float,list(set(row[index] for row in (sorted_data[val] for val in sorted_data.keys())))))\n",
    "    print(\"$$$$$$$$$$$$ \", unique_val_list)\n",
    "    if(len(unique_val_list)==1):\n",
    "        split_mid_pt = unique_val_list[0]\n",
    "        split_mid_pt_gain_ratio = unique_val_list[0]\n",
    "    for i in range(0, len(unique_val_list)-1):\n",
    "        mid_pt = (unique_val_list[i] + unique_val_list[i+1])/2\n",
    "        d1_less = OrderedDict({k:v for (k,v) in sorted_data.items() if float(sorted_data[k][index]) <= mid_pt})\n",
    "        len_less = float(len(d1_less))\n",
    "        d1_more = {k:v for (k,v) in sorted_data.items() if float(sorted_data[k][index]) > mid_pt}\n",
    "        len_more = float(len(d1_more))\n",
    "        sum_less = 0.0\n",
    "        sum_more = 0.0\n",
    "        tot_sum_less = 0.0\n",
    "        tot_sum_more = 0.0\n",
    "        split_info = 0.0\n",
    "        for label_val in labels:\n",
    "            info_less = float([d1_less[row][-1] for row in d1_less.keys()].count(label_val))/len_less\n",
    "            info_more = float([d1_more[row][-1] for row in d1_more.keys()].count(label_val))/len_more\n",
    "            tot_sum_less += float([d1_less[row][-1] for row in d1_less.keys()].count(label_val))\n",
    "            tot_sum_more += float([d1_more[row][-1] for row in d1_more.keys()].count(label_val))\n",
    "            if(info_less != 0):\n",
    "                sum_less += (-1 * info_less * (math.log(info_less)/math.log(2)))\n",
    "            if(info_more != 0):\n",
    "                sum_more += (-1 * info_more * (math.log(info_more)/math.log(2))) \n",
    "        if(tot_sum_less != 0):\n",
    "            tot_sum_less = (-1*(tot_sum_less/len(dict_data))) * math.log(tot_sum_less/len(dict_data))/math.log(2)\n",
    "        if(tot_sum_more != 0):\n",
    "            tot_sum_more = (-1*(tot_sum_more/len(dict_data))) * math.log(tot_sum_more/len(dict_data))/math.log(2)\n",
    "        \n",
    "        #print(\"tot=\",tot_sum_less,tot_sum_more)\n",
    "        cont_info = ((len_less/len_data)*sum_less + (len_more/len_data)*sum_more)\n",
    "        split_info = tot_sum_more + tot_sum_less\n",
    "        gain_ratio = ((entropy - cont_info)/split_info)\n",
    "        if(cont_info < min_cont_info):\n",
    "            min_cont_info = cont_info\n",
    "            split_mid_pt = mid_pt\n",
    "        else:#\n",
    "            print(\"$$$$$$$$$$$$$$$$$$$ \", mid_pt)\n",
    "            split_mid_pt = mid_pt\n",
    "        if(gain_ratio > max_gain_ratio):\n",
    "            max_gain_ratio = gain_ratio\n",
    "            split_mid_pt_gain_ratio = mid_pt\n",
    "    #print(\"MG=\",max_gain_ratio)\n",
    "    return entropy - min_cont_info,split_mid_pt,max_gain_ratio,split_mid_pt_gain_ratio\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function caculates the info gain & gain ratio for categorical data and checks if the data is continuous then continuous info\n",
    "#gain function is called. Function returns the following values:\n",
    "#max_gain - Max info gain\n",
    "#splitting_index - Index(attribute index) with max info gain\n",
    "#max_gain_ratio - Maximum gain ratio(for categorical data)\n",
    "#gain_ratio_splitting_index - Index(attribute index) with max gain ratio\n",
    "#iscontinuous - Tells whether the split pt is categorical or continuous\n",
    "#split_mid_pt - Mid pt of the split. Used in case of continuous data\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "def Info_gain(dict_data,entropy,labels):\n",
    "    info_attr = 0.0\n",
    "    splitting_index = 0\n",
    "    sum_attr = 0.0\n",
    "    max_gain = 0.0\n",
    "    max_gain_ratio = 0.0\n",
    "    gain_ratio = 0.0\n",
    "    gain_ratio_splitting_index = 0\n",
    "    gain = 0\n",
    "    split_mid_pt = 0.0\n",
    "    iscontinuous = False\n",
    "    iscontinuous_gain_ratio = False\n",
    "    key_val = next(iter(dict_data))\n",
    "    #print(\"key=\",len(dict_data[0]))\n",
    "    dict_val_count = OrderedDict()\n",
    "    for i in range (len(dict_data[0])-1):\n",
    "        for key in dict_data.keys():\n",
    "            isdiscrete = True\n",
    "            if(dict_data[key][i].replace('.','').isdigit()):\n",
    "                cont_info_gain,split_mid_pt,gain_ratio,split_mid_pt_gain_ratio = continuous_info_gain(dict_data,i,entropy,labels)\n",
    "                print(\"mid point is \", split_mid_pt)\n",
    "                iscontinuous = True\n",
    "                iscontinuous_gain_ratio = True\n",
    "                isdiscrete = False\n",
    "                if(cont_info_gain > max_gain):\n",
    "                    max_gain = cont_info_gain\n",
    "                    splitting_index = i\n",
    "                if(gain_ratio > max_gain_ratio):\n",
    "                    max_gain_ratio = gain_ratio\n",
    "                    gain_ratio_splitting_index = i\n",
    "                break\n",
    "            else:\n",
    "                if (dict_data[key][i]) not in dict_val_count.keys():\n",
    "                    dict_val_count[dict_data[key][i]] = {}\n",
    "                if(dict_data[key][len(dict_data[0])-1]) not in dict_val_count[dict_data[key][i]].keys():\n",
    "                    dict_val_count[dict_data[key][i]][dict_data[key][len(dict_data[0]) - 1]] = 1\n",
    "                else:\n",
    "                    dict_val_count[dict_data[key][i]][dict_data[key][len(dict_data[0])-1]] += 1\n",
    "        if(isdiscrete == True):\n",
    "            total_info_attr = 0\n",
    "            split_info_attr = 0\n",
    "                #print(dict_val_count)\n",
    "            for key in dict_val_count.keys():\n",
    "                    #print(dict_val_count[key])\n",
    "                info_attr = 0\n",
    "                sum_attr = sum((dict_val_count[key].values()))\n",
    "                val_split = (float(sum_attr)/len(dict_data))\n",
    "                split_info_attr += (-1 * val_split * (math.log(val_split)/math.log(2)))\n",
    "                for key_attr in dict_val_count[key].keys():\n",
    "                    if(sum_attr != 0):\n",
    "                        val = float(dict_val_count[key][key_attr])/sum_attr\n",
    "                        info_attr += (-1*val * (math.log(val)/math.log(2)))\n",
    "                total_info_attr += ((float(sum_attr)/len(dict_data)) * info_attr)\n",
    "                    #print(total_info_attr)\n",
    "            gain = entropy - total_info_attr\n",
    "            if(split_info_attr != 0):\n",
    "                gain_ratio = gain/split_info_attr\n",
    "                #print(gain)\n",
    "                #print(gain_ratio)\n",
    "                dict_val_count.clear()\n",
    "            if(gain > max_gain):\n",
    "                max_gain = gain\n",
    "                splitting_index = i\n",
    "                iscontinuous = False\n",
    "            if(gain_ratio > max_gain_ratio):\n",
    "                max_gain_ratio = gain_ratio\n",
    "                gain_ratio_splitting_index = i\n",
    "                iscontinuous_gain_ratio = False\n",
    "            \n",
    "    return max_gain,splitting_index ,max_gain_ratio,gain_ratio_splitting_index,iscontinuous,iscontinuous_gain_ratio,split_mid_pt,split_mid_pt_gain_ratio      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function returns the unique attribute values for the attribute we split upon\n",
    "def splitting_index_values(dict_data,splitting_index):\n",
    "    unique_val = []\n",
    "    for val in dict_data.keys():\n",
    "        if dict_data[val][splitting_index] not in unique_val:\n",
    "            unique_val.append(dict_data[val][splitting_index])\n",
    "    return unique_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THis function returns the partitoned data for the attribute values we split upon\n",
    "from collections import OrderedDict\n",
    "def get_partition(dict_data,attr_val,splitting_index):\n",
    "    data = OrderedDict()\n",
    "    splitting_index = int(splitting_index)\n",
    "    val = 0\n",
    "    for key in dict_data.keys():\n",
    "        if dict_data[key][splitting_index] in attr_val:\n",
    "            data[val] = {}\n",
    "            data[val] = dict_data[key]\n",
    "            data[val].remove(data[val][splitting_index])\n",
    "            val = val + 1\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THis function returns the partitoned data for the attribute values we split upon. Use it for only continuous data\n",
    "from collections import OrderedDict\n",
    "def get_partition_continuous(dict_data,splitting_index,split_mid_pt):\n",
    "    splitting_index = int(splitting_index)\n",
    "    val = 0\n",
    "    val_more = 0\n",
    "    d_less = OrderedDict()\n",
    "    d_more = OrderedDict()\n",
    "    for key in dict_data.keys():\n",
    "        if float(dict_data[key][splitting_index]) <= split_mid_pt:\n",
    "            d_less[val] = {}\n",
    "            d_less[val] = dict_data[key]\n",
    "            #print(dict_data[key])\n",
    "            d_less[val].remove(d_less[val][splitting_index])\n",
    "            val = val + 1\n",
    "        else:\n",
    "            d_more[val_more] = {}\n",
    "            d_more[val_more] = dict_data[key]\n",
    "            d_more[val_more].remove(d_more[val_more][splitting_index])\n",
    "            val_more = val_more + 1\n",
    "    #print(\"d=\",d_less,d_more)\n",
    "    return d_less,d_more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function returns the gini index for all the unique combinations for each attribute\n",
    "def gini_index(dict_data,attr_set,labels,index):\n",
    "    gini_d = 0.0\n",
    "    gini_attr = 0.0\n",
    "    sum_attr = 0.0\n",
    "    sum_not_attr = 0.0\n",
    "    sum_label = 0.0\n",
    "    sum_not_label = 0.0\n",
    "    len_data = float(len(dict_data))\n",
    "    #print(labels)\n",
    "    for label_val in labels:\n",
    "        p = -1 * [dict_data[row][-1] for row in dict_data.keys()].count(label_val)/len_data\n",
    "        p_attr = -1 * [row[-1] for row in (dict_data[val] for val in dict_data.keys() if dict_data[val][index] in attr_set)].count(label_val)\n",
    "        p_not_attr = -1 * [row[-1] for row in (dict_data[val] for val in dict_data.keys() if dict_data[val][index] not in attr_set)].count(label_val)\n",
    "        sum_label += (-1 * p_attr)\n",
    "        sum_not_label += (-1 * p_not_attr)\n",
    "        sum_attr += float((p_attr * p_attr))\n",
    "        sum_not_attr += float((p_not_attr * p_not_attr)) \n",
    "        gini_d += p*p\n",
    "    if(sum_label != 0):\n",
    "        sum_attr = ((sum_label/len_data) * (1 - ((sum_attr)/(sum_label*sum_label))))\n",
    "    if((sum_not_label) != 0):\n",
    "        sum_not_attr = (((sum_not_label)/len_data) * (1 - ((sum_not_attr)/((sum_not_label)*(sum_not_label)))))\n",
    "        #print(sum_not_attr)\n",
    "    gini_attr = sum_attr + sum_not_attr\n",
    "    gini_d = 1 - gini_d\n",
    "    return gini_d - gini_attr\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THis function returns the gini index for continuous attributes\n",
    "def Gini_Index_Continuous(dict_data,labels,index):\n",
    "    split_md_pt = 0.0\n",
    "    min_con_gini_ind = -10.0\n",
    "    len_data = float(len(dict_data))\n",
    "    sorted_data_list = sorted(dict_data.values(), key=lambda e: e[index], reverse = True)\n",
    "    sorted_data = OrderedDict()\n",
    "    for i in range(0,len(sorted_data_list)):\n",
    "        sorted_data[i] = {}\n",
    "        sorted_data[i] = sorted_data_list[i]\n",
    "    unique_val_list = list(map(float,list(set(row[index] for row in (sorted_data[val] for val in sorted_data.keys())))))\n",
    "    for i in range(0, len(unique_val_list)-1):\n",
    "        mid_pt = (unique_val_list[i] + unique_val_list[i+1])/2\n",
    "        d1_less = OrderedDict({k:v for (k,v) in sorted_data.items() if float(sorted_data[k][index]) <= mid_pt})\n",
    "        len_less = float(len(d1_less))\n",
    "        d1_more = {k:v for (k,v) in sorted_data.items() if float(sorted_data[k][index]) > mid_pt}\n",
    "        len_more = float(len(d1_more))\n",
    "        sum_label = 0.0\n",
    "        sum_not_label = 0.0\n",
    "        sum_attr = 0.0\n",
    "        sum_not_attr = 0.0\n",
    "        gini_d = 0.0\n",
    "        for label_val in labels:\n",
    "            p = -1 * [dict_data[row][-1] for row in dict_data.keys()].count(label_val)/len_data\n",
    "            p_attr = -1 * [row[-1] for row in (dict_data[val] for val in dict_data.keys() if float(dict_data[val][index]) <= mid_pt)].count(label_val)\n",
    "            p_not_attr = -1 * [row[-1] for row in (dict_data[val] for val in dict_data.keys() if float(dict_data[val][index]) > mid_pt)].count(label_val)\n",
    "            sum_label += (-1 * p_attr)\n",
    "            sum_not_label += (-1 * p_not_attr)\n",
    "            sum_attr += float((p_attr * p_attr))\n",
    "            sum_not_attr += float((p_not_attr * p_not_attr)) \n",
    "            gini_d += p*p\n",
    "        if(sum_label != 0):\n",
    "            sum_attr = ((sum_label/len_data) * (1 - ((sum_attr)/(sum_label*sum_label))))\n",
    "            #print(sum_attr)\n",
    "        if((sum_not_label) != 0):\n",
    "            sum_not_attr = (((sum_not_label)/len_data) * (1 - ((sum_not_attr)/((sum_not_label)*(sum_not_label)))))\n",
    "            #print(sum_not_attr)\n",
    "        gini_attr = sum_attr + sum_not_attr\n",
    "        gini_d = 1 - gini_d \n",
    "        gini_index = gini_d - gini_attr\n",
    "        #print(gini_index)\n",
    "        if(min_con_gini_ind < gini_index):\n",
    "            min_con_gini_ind = gini_index\n",
    "            split_md_pt = mid_pt\n",
    "    #print(min_con_gini_ind)\n",
    "    return min_con_gini_ind,split_md_pt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THis function returns the attribute value & index of the attribute with minimum gini val\n",
    "import itertools\n",
    "def get_subset(dict_data,labels):\n",
    "    print(\"D=\",dict_data)\n",
    "    min_gini_index = -10.0\n",
    "    split_attr_val = []\n",
    "    #print(\"gini \", len(dict_data[0]))\n",
    "    for i in range (len(dict_data[0])-1):\n",
    "        if(dict_data[0][i].replace('.','').isdigit()):\n",
    "                cont_gini_index,split_mid_pt_gini = Gini_Index_Continuous(dict_data,labels,i)\n",
    "                if(min_gini_index < cont_gini_index):\n",
    "                    min_gini_index = cont_gini_index\n",
    "                    iscontinuous_gini = True\n",
    "                    split_index_gini = i\n",
    "        else:\n",
    "            attr_val = splitting_index_values(dict_data,i)\n",
    "            for j in range(1,len(attr_val)):\n",
    "                z = list(itertools.combinations(attr_val,j))\n",
    "                for k in range(0,len(z)):\n",
    "                    gini_ind = gini_index(dict_data,z[k],labels,i)\n",
    "                    if(min_gini_index < gini_ind):\n",
    "                        min_gini_index = gini_ind\n",
    "                        split_attr_val = z[k]\n",
    "                        iscontinuous_gini = False\n",
    "                        split_index_gini = i\n",
    "    return min_gini_index,split_attr_val,split_index_gini,iscontinuous_gini,split_mid_pt_gini\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree_Node:\n",
    "    def __init__(self,question,parent_decision):\n",
    "        self.name = question\n",
    "        self.parent_decision = parent_decision\n",
    "        self.children = {}\n",
    "        self.isconctinuous = False\n",
    "        self.split = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def gen_Tree(dict_org, labels, attrList, parent_decision, function):#does labels get updated for partitions?\n",
    "    dict_copy = dict_org.copy()\n",
    "    attrList_copy = attrList\n",
    "    #print(\"recur\")\n",
    "    N = Tree_Node(None, parent_decision)\n",
    "    x=0\n",
    "    tempClass = dict_org[x][-1]\n",
    "    while(dict_org[x][-1] == tempClass):\n",
    "        if(x == len(dict_org)-1):\n",
    "            N.name = tempClass\n",
    "            return N\n",
    "        x+=1\n",
    "    if(len(attrList_copy)==0):\n",
    "        N.name = getMajorityClass(dict_org)\n",
    "        return N\n",
    "    entropy=Entropy(dict_org)\n",
    "    if function == 0:#info gain\n",
    "        max_gain,splitting_index ,max_gain_ratio,gain_ratio_splitting_index,iscontinuous,iscontinuous_gain_ratio,split_mid_pt,split_mid_pt_gain_ratio = Info_gain(dict_org,entropy,labels)\n",
    "    elif function == 1:#gain ratio\n",
    "        max_gain,splitting_index ,max_gain_ratio,gain_ratio_splitting_index,iscontinuous,iscontinuous_gain_ratio,split_mid_pt,split_mid_pt_gain_ratio = Info_gain(dict_org,entropy,labels)\n",
    "        splitting_index = gain_ratio_splitting_index\n",
    "        iscontinuous = iscontinuous_gain_ratio\n",
    "        split_mid_pt = split_mid_pt_gain_ratio\n",
    "    elif function == 2:#gini\n",
    "        min_gini_index,split_attr_val,splitting_index,iscontinuous,split_mid_pt = get_subset(dict_org,labels)\n",
    "    print(dict_org)\n",
    "    print(len(attrList_copy), splitting_index, iscontinuous)\n",
    "    N.name = attrList_copy[splitting_index]\n",
    "    N.iscontinuous = iscontinuous\n",
    "    N.split = split_mid_pt\n",
    "    attrList_copy.pop(splitting_index)#attributes are not being looked at explicitly in ths function\n",
    "    if(iscontinuous):\n",
    "        print(\"attr \", attrList[splitting_index], \" is continuous\")\n",
    "        thePartitions = [0,0]\n",
    "        thePartitions[0], thePartitions[1] = get_partition_continuous(dict_org, splitting_index, split_mid_pt)\n",
    "        unique_split_val = [(\"<= \" + str(split_mid_pt)), (\"> \" + str(split_mid_pt))]\n",
    "    else:\n",
    "        thePartitions = []\n",
    "        unique_split_val = splitting_index_values(dict_org,splitting_index)\n",
    "        for x in unique_split_val:\n",
    "            thePartitions.append(get_partition(dict_org, x, splitting_index))\n",
    "    count1=0\n",
    "    for x in thePartitions:\n",
    "        if(len(x) == 0):#this condition has not been tested yet\n",
    "            N.children[unique_split_val[count1]] = Tree_Node(getMajorityClass(dict_copy), unique_split_val[count1])\n",
    "        else:\n",
    "            print(\"partition \", x)\n",
    "            N.children[unique_split_val[count1]] = gen_Tree(x, labels, attrList_copy, unique_split_val[count1], function)\n",
    "        count1+=1\n",
    "    #print(N.name, \" has \",len(N.children), \" children. They are:\")\n",
    "    #for child in N.children:\n",
    "        #print(N.children[child].name)\n",
    "    return N\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#unique_val_list = list(map(float,list(set(row[index] for row in (sorted_data[val] for val in sorted_data.keys())))))\n",
    "#gives the amount of attribute values for a given attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMajorityClass(dict_org):\n",
    "    theClasses = {}\n",
    "    majority = \"\"\n",
    "    for x in dict_org.values():\n",
    "        if(x[-1] not in theClasses):\n",
    "            theClasses[x[-1]] = 1\n",
    "        else:\n",
    "            theClasses[x[-1]] += 1\n",
    "    y=0\n",
    "    for x in theClasses:\n",
    "        if(theClasses[x] > y):\n",
    "            y = theClasses[x]\n",
    "            majority = x\n",
    "    return majority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printTree(Node):\n",
    "    print(\"---\")\n",
    "    print(\"Current question is \", Node.name)\n",
    "    print(\"Previous decision is \", Node.parent_decision)\n",
    "    if len(Node.children)==0:\n",
    "        print(\"this is the leaf result\")\n",
    "        return\n",
    "    for child in Node.children:\n",
    "        printTree(Node.children[child])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLearningSetAndTestingSet(org_dict, ratio):\n",
    "    LearningSetLength = int(len(org_dict)*ratio)\n",
    "    LearningSet = {}\n",
    "    TestingSet = {}\n",
    "    for x in range(len(org_dict)):\n",
    "        if x <= LearningSetLength:\n",
    "            LearningSet[x] = org_dict[x]\n",
    "        else:\n",
    "            TestingSet[x-LearningSetLength-1] = org_dict[x]\n",
    "    return LearningSet, TestingSet\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestWithTree(TestEntry, decisionTree, majority):\n",
    "    if len(decisionTree.children) == 0:\n",
    "        return decisionTree.name\n",
    "    else:\n",
    "        #print(\"testing entry is \", TestEntry)\n",
    "        if decisionTree.iscontinuous == False:\n",
    "            #print(\"question is \", decisionTree.name)\n",
    "            #print(\"testing entry answer is \", TestEntry[decisionTree.name])\n",
    "            #print(\"question's options are \", decisionTree.children)\n",
    "            if TestEntry[decisionTree.name] in decisionTree.children.keys():\n",
    "                #print(decisionTree.children[TestEntry[decisionTree.name]])\n",
    "                return TestWithTree(TestEntry, decisionTree.children[TestEntry[decisionTree.name]], majority)\n",
    "            else:\n",
    "                #print(\"cant find answer, majority is \", majority)\n",
    "                return majority\n",
    "            \n",
    "        else:\n",
    "            #print(\"question is <= or > \", decisionTree.split)\n",
    "            #print(\"testing entry answer is \", TestEntry[decisionTree.name])\n",
    "            if Decimal(TestEntry[decisionTree.name]) <= decisionTree.split:\n",
    "                #print(decisionTree.children[(\"<= \" + str(decisionTree.split))])\n",
    "                return TestWithTree(TestEntry, decisionTree.children[(\"<= \" + str(decisionTree.split))], majority)\n",
    "            else:\n",
    "                #print(decisionTree.children[(\"> \" + str(decisionTree.split))])\n",
    "                return TestWithTree(TestEntry, decisionTree.children[(\"> \" + str(decisionTree.split))], majority)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ['2', 'youth', 'high', 'no', 'fair', 'no'], 1: ['1', 'youth', 'high', 'no', 'excellent', 'no'], 2: ['1', 'middle aged', 'high', 'no', 'fair', 'yes'], 3: ['2', 'senior', 'medium', 'no', 'fair', 'yes'], 4: ['2', 'senior', 'low', 'yes', 'fair', 'yes'], 5: ['1', 'senior', 'low', 'yes', 'excellent', 'no'], 6: ['1', 'middle aged', 'low', 'yes', 'excellent', 'yes'], 7: ['1', 'youth', 'medium', 'no', 'fair', 'no'], 8: ['2', 'youth', 'low', 'yes', 'fair', 'yes'], 9: ['2', 'senior', 'medium', 'yes', 'fair', 'yes'], 10: ['1', 'youth', 'medium', 'yes', 'excellent', 'yes'], 11: ['1', 'middle aged', 'medium', 'no', 'excellent', 'yes'], 12: ['2', 'middle aged', 'high', 'yes', 'fair', 'yes'], 13: ['1', 'senior', 'medium', 'no', 'excellent', 'no']}\n",
      "$$$$$$$$$$$$  [1.0, 2.0]\n",
      "mid point is  1.5\n",
      "++++\n",
      "++++\n",
      "{0: ['2', 'youth', 'high', 'no', 'fair', 'no'], 1: ['1', 'youth', 'high', 'no', 'excellent', 'no'], 2: ['1', 'middle aged', 'high', 'no', 'fair', 'yes'], 3: ['2', 'senior', 'medium', 'no', 'fair', 'yes'], 4: ['2', 'senior', 'low', 'yes', 'fair', 'yes'], 5: ['1', 'senior', 'low', 'yes', 'excellent', 'no'], 6: ['1', 'middle aged', 'low', 'yes', 'excellent', 'yes'], 7: ['1', 'youth', 'medium', 'no', 'fair', 'no'], 8: ['2', 'youth', 'low', 'yes', 'fair', 'yes'], 9: ['2', 'senior', 'medium', 'yes', 'fair', 'yes']}\n",
      "[0, 1, 2, 3, 4]\n",
      "start\n",
      "$$$$$$$$$$$$  [1.0, 2.0]\n",
      "mid point is  1.5\n",
      "{0: ['2', 'youth', 'high', 'no', 'fair', 'no'], 1: ['1', 'youth', 'high', 'no', 'excellent', 'no'], 2: ['1', 'middle aged', 'high', 'no', 'fair', 'yes'], 3: ['2', 'senior', 'medium', 'no', 'fair', 'yes'], 4: ['2', 'senior', 'low', 'yes', 'fair', 'yes'], 5: ['1', 'senior', 'low', 'yes', 'excellent', 'no'], 6: ['1', 'middle aged', 'low', 'yes', 'excellent', 'yes'], 7: ['1', 'youth', 'medium', 'no', 'fair', 'no'], 8: ['2', 'youth', 'low', 'yes', 'fair', 'yes'], 9: ['2', 'senior', 'medium', 'yes', 'fair', 'yes']}\n",
      "5 1 False\n",
      "partition  OrderedDict([(0, ['2', 'high', 'no', 'fair', 'no']), (1, ['1', 'high', 'no', 'excellent', 'no']), (2, ['1', 'medium', 'no', 'fair', 'no']), (3, ['2', 'low', 'yes', 'fair', 'yes'])])\n",
      "$$$$$$$$$$$$  [1.0, 2.0]\n",
      "mid point is  1.5\n",
      "OrderedDict([(0, ['2', 'high', 'no', 'fair', 'no']), (1, ['1', 'high', 'no', 'excellent', 'no']), (2, ['1', 'medium', 'no', 'fair', 'no']), (3, ['2', 'low', 'yes', 'fair', 'yes'])])\n",
      "4 2 False\n",
      "partition  OrderedDict([(0, ['2', 'high', 'fair', 'no']), (1, ['1', 'high', 'excellent', 'no']), (2, ['1', 'medium', 'fair', 'no'])])\n",
      "partition  OrderedDict([(0, ['2', 'low', 'fair', 'yes'])])\n",
      "partition  OrderedDict([(0, ['1', 'high', 'no', 'fair', 'yes']), (1, ['1', 'low', 'yes', 'excellent', 'yes'])])\n",
      "partition  OrderedDict([(0, ['2', 'medium', 'no', 'fair', 'yes']), (1, ['2', 'low', 'yes', 'fair', 'yes']), (2, ['1', 'low', 'yes', 'excellent', 'no']), (3, ['2', 'medium', 'yes', 'fair', 'yes'])])\n",
      "$$$$$$$$$$$$  [1.0, 2.0]\n",
      "mid point is  1.5\n",
      "OrderedDict([(0, ['2', 'medium', 'no', 'fair', 'yes']), (1, ['2', 'low', 'yes', 'fair', 'yes']), (2, ['1', 'low', 'yes', 'excellent', 'no']), (3, ['2', 'medium', 'yes', 'fair', 'yes'])])\n",
      "3 0 True\n",
      "attr  2  is continuous\n",
      "partition  OrderedDict([(0, ['low', 'yes', 'excellent', 'no'])])\n",
      "partition  OrderedDict([(0, ['medium', 'no', 'fair', 'yes']), (1, ['low', 'yes', 'fair', 'yes']), (2, ['medium', 'yes', 'fair', 'yes'])])\n",
      "finished\n",
      "---\n",
      "Current question is  1\n",
      "Previous decision is  None\n",
      "---\n",
      "Current question is  3\n",
      "Previous decision is  youth\n",
      "---\n",
      "Current question is  no\n",
      "Previous decision is  no\n",
      "this is the leaf result\n",
      "---\n",
      "Current question is  yes\n",
      "Previous decision is  yes\n",
      "this is the leaf result\n",
      "---\n",
      "Current question is  yes\n",
      "Previous decision is  middle aged\n",
      "this is the leaf result\n",
      "---\n",
      "Current question is  0\n",
      "Previous decision is  senior\n",
      "---\n",
      "Current question is  no\n",
      "Previous decision is  <= 1.5\n",
      "this is the leaf result\n",
      "---\n",
      "Current question is  yes\n",
      "Previous decision is  > 1.5\n",
      "this is the leaf result\n",
      "{0: ['1', 'youth', 'medium', 'yes', 'excellent', 'yes'], 1: ['1', 'middle aged', 'medium', 'no', 'excellent', 'yes'], 2: ['2', 'middle aged', 'high', 'yes', 'fair', 'yes'], 3: ['1', 'senior', 'medium', 'no', 'excellent', 'no']}\n",
      "accuracy is  1.0\n"
     ]
    }
   ],
   "source": [
    "from decimal import Decimal\n",
    "\n",
    "dict_org, labels = readData()\n",
    "entropy = Entropy(dict_org)\n",
    "#print(labels)\n",
    "print(dict_org)\n",
    "max_gain,splitting_index,max_gain_ratio,gain_ratio_splitting_index,iscontinuous,iscontinuous_gain_ratio,split_mid_pt,split_mid_pt_gain_ratio= Info_gain(dict_org,entropy,labels)\n",
    "    #return max_gain,splitting_index ,max_gain_ratio,gain_ratio_splitting_index,iscontinuous,iscontinuous_gain_ratio,split_mid_pt,split_mid_pt_gain_ratio      \n",
    "#print(iscontinuous_gain_ratio,split_mid_pt_gain_ratio,max_gain_ratio)\n",
    "#iscontinuous_gain_ratio,split_mid_pt,split_mid_pt_gain_ratio  \n",
    "#print(dict_data)\n",
    "#min_gini_index,split_attr_val,split_index_gini,iscontinuous_gini,split_mid_pt_gini = get_subset(dict_org,labels)\n",
    "\n",
    "print(\"++++\")\n",
    "#print(max_gain,splitting_index,max_gain_ratio,gain_ratio_splitting_index,iscontinuous,split_mid_pt)\n",
    "#print(min_gini_index,split_attr_val,split_index_gini,iscontinuous_gini,split_mid_pt_gini)\n",
    "print(\"++++\")\n",
    "\n",
    "LearningSet, TestingSet = getLearningSetAndTestingSet(dict_org, 0.7)\n",
    "print(LearningSet)\n",
    "#print(TestingSet)\n",
    "majority = getMajorityClass(LearningSet)\n",
    "\n",
    "attrNum=len(LearningSet[0])-1\n",
    "attrList = []\n",
    "for x in range(attrNum):\n",
    "    attrList.append(x)\n",
    "print(attrList)\n",
    "\n",
    "print(\"start\")\n",
    "theTree=gen_Tree(LearningSet, labels, attrList, None, 1)\n",
    "print(\"finished\")\n",
    "printTree(theTree)\n",
    "\n",
    "\n",
    "print(TestingSet)\n",
    "success=0\n",
    "for x in TestingSet:\n",
    "    if TestWithTree(TestingSet[x], theTree, majority) == TestingSet[x][-1]:\n",
    "        success+=1\n",
    "accuracy = success/len(TestingSet)\n",
    "print(\"accuracy is \", accuracy)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
